{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eed3ee501ea74c3c889fc8dd79fd013e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_208af020ef44413ca2c949a7cdf59eba",
              "IPY_MODEL_3903500e20a14c70bc4ef69933639987",
              "IPY_MODEL_15630a79f55744be92b8848e474b31e5"
            ],
            "layout": "IPY_MODEL_49ea322473134858a7c5feefd83ee167"
          }
        },
        "208af020ef44413ca2c949a7cdf59eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838a3659b798405f8244fa00ea8008bc",
            "placeholder": "​",
            "style": "IPY_MODEL_ddc42582b44e49c19ffc1b690fc0be4f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3903500e20a14c70bc4ef69933639987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6d1d987b4f48169c7085c0fb11c75a",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df844a4745e64c6a9769920da0eada90",
            "value": 25
          }
        },
        "15630a79f55744be92b8848e474b31e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db2288d97cc48cfb01abe10f849c0c2",
            "placeholder": "​",
            "style": "IPY_MODEL_ff756ef93f124a5f9a715d15a1051178",
            "value": " 25.0/25.0 [00:00&lt;00:00, 790B/s]"
          }
        },
        "49ea322473134858a7c5feefd83ee167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838a3659b798405f8244fa00ea8008bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc42582b44e49c19ffc1b690fc0be4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b6d1d987b4f48169c7085c0fb11c75a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df844a4745e64c6a9769920da0eada90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5db2288d97cc48cfb01abe10f849c0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff756ef93f124a5f9a715d15a1051178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67a7706a7fa4cd293a4fee12147ff03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf1a2ca505c04aaa8a2918b9bc0b15d6",
              "IPY_MODEL_5033f4226c57491b9c0d995e1fd531d5",
              "IPY_MODEL_cfedbb5998394d858f22bd0885cb3355"
            ],
            "layout": "IPY_MODEL_898ea0969d2b4f7c96d2f635c7192df2"
          }
        },
        "cf1a2ca505c04aaa8a2918b9bc0b15d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6cabb55d61547868f038edf8119c26b",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ceff1a3800410097846afc748ba55a",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "5033f4226c57491b9c0d995e1fd531d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50e44610568a4a45a6a8e5feaf9f3f28",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdd6b0fdae57405ba8b9c3399fcd52c5",
            "value": 5069051
          }
        },
        "cfedbb5998394d858f22bd0885cb3355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580e27d26c264861a997229381d6abb5",
            "placeholder": "​",
            "style": "IPY_MODEL_cc251a184ee84d26947f4f7308b3e1b1",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 34.2MB/s]"
          }
        },
        "898ea0969d2b4f7c96d2f635c7192df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cabb55d61547868f038edf8119c26b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ceff1a3800410097846afc748ba55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50e44610568a4a45a6a8e5feaf9f3f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd6b0fdae57405ba8b9c3399fcd52c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "580e27d26c264861a997229381d6abb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc251a184ee84d26947f4f7308b3e1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b1287629b874e1a9407007901c86f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec1719cdd6f24e47950de02b6de82209",
              "IPY_MODEL_974e9bf88de549ccb16f5a036789e5e9",
              "IPY_MODEL_204fec0578804b5c9028b831905d0293"
            ],
            "layout": "IPY_MODEL_1b6f2c3d34814eea9a717f6854f969a3"
          }
        },
        "ec1719cdd6f24e47950de02b6de82209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35660ad0df9a4edb959d1a8056f3a124",
            "placeholder": "​",
            "style": "IPY_MODEL_3717edbe68c94507a9745e97e2d8401f",
            "value": "tokenizer.json: 100%"
          }
        },
        "974e9bf88de549ccb16f5a036789e5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917732e8b95444359d0aec78c07696e7",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bb01edef217419b8138a2f07541697c",
            "value": 9096718
          }
        },
        "204fec0578804b5c9028b831905d0293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f01fcce132452cad346c182a729032",
            "placeholder": "​",
            "style": "IPY_MODEL_c65a0b9df74f4fefba91a503a5cf9645",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 38.4MB/s]"
          }
        },
        "1b6f2c3d34814eea9a717f6854f969a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35660ad0df9a4edb959d1a8056f3a124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3717edbe68c94507a9745e97e2d8401f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "917732e8b95444359d0aec78c07696e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb01edef217419b8138a2f07541697c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20f01fcce132452cad346c182a729032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65a0b9df74f4fefba91a503a5cf9645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af3ef09a491f420586469c486c3d7df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f51fd5f12fa9489cb08ed52bba167e54",
              "IPY_MODEL_bbdd4fa5e2ef4494868dbc4bd408d172",
              "IPY_MODEL_fd1c0f457f4a4828ac0bb34f408fc4de"
            ],
            "layout": "IPY_MODEL_9ff096538ec2443eb4531fdeb9d2dd14"
          }
        },
        "f51fd5f12fa9489cb08ed52bba167e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7b584f9e194446789f8eefe04232003",
            "placeholder": "​",
            "style": "IPY_MODEL_734c1e9a90e94c48a750de6e80d60763",
            "value": "config.json: 100%"
          }
        },
        "bbdd4fa5e2ef4494868dbc4bd408d172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b74d6fe14d3b4ca59d3b172365ee7f6a",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_918820a8c5244d4896407348785e85b1",
            "value": 615
          }
        },
        "fd1c0f457f4a4828ac0bb34f408fc4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155542cdebeb4942b0cdde83f6160484",
            "placeholder": "​",
            "style": "IPY_MODEL_d951b675c636430097cf24acd6ca3726",
            "value": " 615/615 [00:00&lt;00:00, 44.0kB/s]"
          }
        },
        "9ff096538ec2443eb4531fdeb9d2dd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b584f9e194446789f8eefe04232003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734c1e9a90e94c48a750de6e80d60763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74d6fe14d3b4ca59d3b172365ee7f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918820a8c5244d4896407348785e85b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "155542cdebeb4942b0cdde83f6160484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d951b675c636430097cf24acd6ca3726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-tiR65Il8-c",
        "outputId": "bb9ccaa0-b499-43af-f3e1-ff75f127d617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets --quiet\n",
        "!pip install torchtext --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n"
      ],
      "metadata": {
        "id": "_cgIOxcDmHxv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "data = []\n",
        "with open(\"/content/urdu-sentiment-corpus-v1.tsv.txt\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()[1:]  # Skip header\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        # Match label as the last token: P or N\n",
        "        match = re.match(r\"^(.*)\\s([PN])$\", line)\n",
        "        if match:\n",
        "            text = match.group(1).strip()\n",
        "            label = 1 if match.group(2) == 'P' else 0\n",
        "            data.append((text, label))\n",
        "\n",
        "# Create DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "print(\"Number of samples:\", len(df))\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "w85xacVBmKV_",
        "outputId": "00a80e8e-b1e7-40b7-c2e7-858dfe01e7d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...      1\n",
              "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...      0\n",
              "2  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...      1\n",
              "3    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ      1\n",
              "4  گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے هو...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c52972cb-3b9b-47cf-97b1-dcae6ead5fcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے هو...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c52972cb-3b9b-47cf-97b1-dcae6ead5fcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c52972cb-3b9b-47cf-97b1-dcae6ead5fcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c52972cb-3b9b-47cf-97b1-dcae6ead5fcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2ca47977-b592-447a-bbb3-8c36d3cb7cc0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ca47977-b592-447a-bbb3-8c36d3cb7cc0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2ca47977-b592-447a-bbb3-8c36d3cb7cc0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 980,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 978,\n        \"samples\": [\n          \"\\u0644\\u06af\\u062a\\u0627 \\u06c1\\u06d2 \\u0622\\u0633\\u0679\\u0631\\u06cc\\u0644\\u06cc\\u0627 \\u06a9\\u06cc \\u0679\\u06cc\\u0645 \\u0628\\u06c1\\u062a \\u0628\\u0631\\u0627 \\u067e\\u0631\\u0641\\u0627\\u0631\\u0645 \\u06a9\\u0631 \\u0631\\u06c1\\u06cc \\u06c1\\u06d2 \\u06d4 \\u06c1\\u0645\\u0627\\u0631\\u06cc \\u062d\\u0627\\u0644\\u062a \\u062a\\u0648 \\u062c\\u0648\\u06ba \\u06a9\\u06cc \\u062a\\u0648\\u06ba \\u06c1\\u06d2\",\n          \"\\u06c1\\u0645\\u06cc\\u06ba \\u0622\\u062c \\u067e\\u062a\\u0627 \\u0686\\u0644\\u0627 \\u06a9\\u06c1 \\u0627\\u0633 \\u0644\\u0639\\u0646\\u062a\\u06cc \\u0627\\u0628\\u0648 \\u0644\\u0648\\u0644\\u0648 \\u0641\\u06cc\\u0631\\u0648\\u0632 \\u06a9\\u0627 \\u0645\\u0632\\u0627\\u0631 \\u0628\\u06be\\u06cc \\u06c1\\u06d2 \\u0627\\u06cc\\u0631\\u0627\\u0646 \\u0645\\u06cc\\u06ba \\u06d4\\u06d4 \\u062d\\u06cc\\u0631\\u062a \\u06c1\\u06d2 \\u06d4\\u06d4\",\n          \"\\u0645\\u062d\\u0631\\u0645 \\u0627\\u0644\\u062d\\u0631\\u0627\\u0645 \\u06a9\\u0627 \\u0686\\u0627\\u0646\\u062f \\u0646\\u0638\\u0631 \\u0622 \\u06af\\u06cc\\u0627\\u060c \\u06cc\\u0648\\u0645 \\u0639\\u0627\\u0634\\u0648\\u0631\\u06c1 \\u0686\\u0627\\u0631 \\u0646\\u0648\\u0645\\u0628\\u0631 \\u06a9\\u0648 \\u06c1\\u0648\\u06af\\u0627\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text'].values\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "wAlveHI5mMQR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "max_len = 50\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Dataset class\n",
        "class UrduDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        sequences = tokenizer.texts_to_sequences(texts)\n",
        "        self.X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "        self.y = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.float)\n"
      ],
      "metadata": {
        "id": "JFqhBaCGmPMm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = UrduDataset(X_train, y_train)\n",
        "test_data = UrduDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n"
      ],
      "metadata": {
        "id": "jnhzcMs9mR6Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers=1, dropout=0.3):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, nonlinearity='tanh')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        out = self.dropout(hidden[-1])  # Last hidden state\n",
        "        out = self.fc(out)\n",
        "        return self.sigmoid(out)\n"
      ],
      "metadata": {
        "id": "BlaSa4ppmYfm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = RNNModel(vocab_size, embed_dim=128, hidden_dim=64, output_dim=1).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "1oLemwO3m1Ay"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "iMHOQUJKnD5X"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            probs = outputs.cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds)\n",
        "    rec = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall: {rec:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    return acc, prec, rec, f1\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, device, epochs=10)\n",
        "evaluate_model(model, test_loader, device)\n"
      ],
      "metadata": {
        "id": "y_WdD4-knDcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a726662-ef44-484d-bbc9-5df65ace4330"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 15.9787\n",
            "Epoch 2/10, Loss: 15.9843\n",
            "Epoch 3/10, Loss: 15.9257\n",
            "Epoch 4/10, Loss: 15.9551\n",
            "Epoch 5/10, Loss: 15.9707\n",
            "Epoch 6/10, Loss: 15.9572\n",
            "Epoch 7/10, Loss: 15.9798\n",
            "Epoch 8/10, Loss: 15.9583\n",
            "Epoch 9/10, Loss: 15.9774\n",
            "Epoch 10/10, Loss: 15.9451\n",
            "Accuracy: 0.5143\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1 Score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5142857142857142, 0.0, 0.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()[1:]  # Skip header\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            # Match label as the last token: P or N\n",
        "            match = re.match(r\"^(.*)\\s([PN])$\", line)\n",
        "            if match:\n",
        "                text = match.group(1).strip()\n",
        "                label = 1 if match.group(2) == 'P' else 0\n",
        "                data.append((text, label))\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "\n",
        "# Load data\n",
        "df = load_data(\"urdu-sentiment-corpus-v1.tsv.txt\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "max_words = 10000  # Maximum number of words to keep\n",
        "max_len = 100      # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# GRU Model\n",
        "embedding_dim = 128\n",
        "gru_units = 64\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len),\n",
        "    GRU(units=gru_units, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Save model for later use\n",
        "model.save('urdu_sentiment_gru.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCp5GGfvi0D-",
        "outputId": "79355cfd-c63f-472d-808f-ecca31ab15ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 9s 239ms/step - loss: 0.6930 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5646\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 0.6660 - accuracy: 0.7976 - val_loss: 0.6840 - val_accuracy: 0.5714\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 4s 229ms/step - loss: 0.5305 - accuracy: 0.8793 - val_loss: 0.6874 - val_accuracy: 0.5646\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 4s 202ms/step - loss: 0.2449 - accuracy: 0.9626 - val_loss: 0.7494 - val_accuracy: 0.5714\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 0.0754 - accuracy: 0.9847 - val_loss: 1.0121 - val_accuracy: 0.5646\n",
            "8/8 [==============================] - 1s 21ms/step\n",
            "Accuracy: 0.5429\n",
            "Precision: 0.5347\n",
            "Recall: 0.4538\n",
            "F1-score: 0.4909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Reusing  the same preprocessing from GRU (X_train_pad, X_test_pad, y_train, y_test)\n",
        "# Load and preprocess data\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()[1:]  # Skip header\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            # Match label as the last token: P or N\n",
        "            match = re.match(r\"^(.*)\\s([PN])$\", line)\n",
        "            if match:\n",
        "                text = match.group(1).strip()\n",
        "                label = 1 if match.group(2) == 'P' else 0\n",
        "                data.append((text, label))\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "\n",
        "# Load data\n",
        "df = load_data(\"urdu-sentiment-corpus-v1.tsv.txt\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization\n",
        "max_words = 10000  # Maximum number of words to keep\n",
        "max_len = 100      # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# LSTM Model\n",
        "lstm_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=256, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(128, dropout=0.3, recurrent_dropout=0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = lstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_pred = (lstm_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"LSTM Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"recall_score: {recall_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQPhxmYbi0IX",
        "outputId": "e7a7c91e-6957-4134-a4c0-22b0003b7ba5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "19/19 [==============================] - 16s 505ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5034\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 14s 705ms/step - loss: 0.6915 - accuracy: 0.5578 - val_loss: 0.6927 - val_accuracy: 0.5170\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 15s 766ms/step - loss: 0.6898 - accuracy: 0.6293 - val_loss: 0.6922 - val_accuracy: 0.4966\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 12s 634ms/step - loss: 0.6894 - accuracy: 0.6037 - val_loss: 0.6918 - val_accuracy: 0.5102\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 9s 438ms/step - loss: 0.6863 - accuracy: 0.7024 - val_loss: 0.6914 - val_accuracy: 0.5986\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 10s 520ms/step - loss: 0.6834 - accuracy: 0.7143 - val_loss: 0.6905 - val_accuracy: 0.5850\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 10s 515ms/step - loss: 0.6790 - accuracy: 0.7483 - val_loss: 0.6891 - val_accuracy: 0.5918\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 8s 426ms/step - loss: 0.6710 - accuracy: 0.7313 - val_loss: 0.6869 - val_accuracy: 0.5714\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 10s 506ms/step - loss: 0.6545 - accuracy: 0.7823 - val_loss: 0.6855 - val_accuracy: 0.5442\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 9s 499ms/step - loss: 0.6259 - accuracy: 0.7585 - val_loss: 0.6768 - val_accuracy: 0.5510\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 10s 510ms/step - loss: 0.5601 - accuracy: 0.8690 - val_loss: 0.7084 - val_accuracy: 0.5034\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 9s 445ms/step - loss: 0.5272 - accuracy: 0.7993 - val_loss: 0.6668 - val_accuracy: 0.6395\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 11s 606ms/step - loss: 0.4423 - accuracy: 0.9422 - val_loss: 0.6722 - val_accuracy: 0.5918\n",
            "Epoch 14/15\n",
            "19/19 [==============================] - 9s 498ms/step - loss: 0.3309 - accuracy: 0.9116 - val_loss: 0.6744 - val_accuracy: 0.5986\n",
            "Epoch 15/15\n",
            "19/19 [==============================] - 8s 425ms/step - loss: 0.2548 - accuracy: 0.9575 - val_loss: 0.7696 - val_accuracy: 0.5782\n",
            "8/8 [==============================] - 1s 54ms/step\n",
            "LSTM Metrics:\n",
            "Accuracy: 0.5959\n",
            "F1-score: 0.4975\n",
            "Precision: 0.6282\n",
            "recall_score: 0.4118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BiLSTM Model\n",
        "bilstm_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(max_words, 256, input_length=max_len),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.3)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "bilstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = bilstm_model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_pred = (bilstm_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"BiLSTM Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"recall_score: {recall_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToRMrEEd8HiS",
        "outputId": "3c6de411-0af9-452e-a8d0-cefa29aa054a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "19/19 [==============================] - 32s 1s/step - loss: 0.6939 - accuracy: 0.4728 - val_loss: 0.6935 - val_accuracy: 0.4762\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 17s 881ms/step - loss: 0.6938 - accuracy: 0.4490 - val_loss: 0.6933 - val_accuracy: 0.4762\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 16s 859ms/step - loss: 0.6922 - accuracy: 0.5238 - val_loss: 0.6928 - val_accuracy: 0.5510\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 18s 951ms/step - loss: 0.6925 - accuracy: 0.5459 - val_loss: 0.6925 - val_accuracy: 0.5714\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 16s 876ms/step - loss: 0.6902 - accuracy: 0.5748 - val_loss: 0.6922 - val_accuracy: 0.5578\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 16s 859ms/step - loss: 0.6879 - accuracy: 0.6156 - val_loss: 0.6915 - val_accuracy: 0.5646\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 17s 889ms/step - loss: 0.6825 - accuracy: 0.6599 - val_loss: 0.6898 - val_accuracy: 0.5714\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 18s 889ms/step - loss: 0.6666 - accuracy: 0.7602 - val_loss: 0.6856 - val_accuracy: 0.5646\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 16s 870ms/step - loss: 0.6231 - accuracy: 0.7568 - val_loss: 0.7012 - val_accuracy: 0.4830\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 17s 892ms/step - loss: 0.5483 - accuracy: 0.7891 - val_loss: 0.6731 - val_accuracy: 0.5714\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 19s 973ms/step - loss: 0.3814 - accuracy: 0.9014 - val_loss: 0.7471 - val_accuracy: 0.5646\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 17s 880ms/step - loss: 0.1712 - accuracy: 0.9660 - val_loss: 1.1028 - val_accuracy: 0.6463\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 17s 911ms/step - loss: 0.1524 - accuracy: 0.9575 - val_loss: 0.9621 - val_accuracy: 0.6190\n",
            "8/8 [==============================] - 5s 197ms/step\n",
            "BiLSTM Metrics:\n",
            "Accuracy: 0.6449\n",
            "F1-score: 0.6926\n",
            "Precision: 0.5976\n",
            "recall_score: 0.8235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow==2.12.0 keras==2.12.0 transformers==4.30.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X1Qg0b1D6WN",
        "outputId": "4d4eb520-96b1-4d8b-cf3a-6c8418f7a4c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: transformers==4.30.0 in /usr/local/lib/python3.11/dist-packages (4.30.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2025.3.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2025.4.26)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow==2.12.0 keras==2.12.0 transformers==4.30.0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()[1:]  # Skip header\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            match = re.match(r\"^(.*)\\s([PN])$\", line)\n",
        "            if match:\n",
        "                text = match.group(1).strip()\n",
        "                label = 1 if match.group(2) == 'P' else 0\n",
        "                data.append((text, label))\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "\n",
        "# Load data\n",
        "df = load_data(\"urdu-sentiment-corpus-v1.tsv.txt\")\n",
        "\n",
        "# Split data (THIS IS WHAT WAS MISSING)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# 2. mBERT Implementation\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "def encode_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "X_train_enc = encode_texts(X_train)\n",
        "X_test_enc = encode_texts(X_test)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'input_ids': X_train_enc['input_ids'],\n",
        "        'attention_mask': X_train_enc['attention_mask']\n",
        "    },\n",
        "    y_train\n",
        ")).shuffle(1000).batch(8)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'input_ids': X_test_enc['input_ids'],\n",
        "        'attention_mask': X_test_enc['attention_mask']\n",
        "    },\n",
        "    y_test\n",
        ")).batch(8)\n",
        "\n",
        "# Load model\n",
        "model = TFBertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-multilingual-cased',\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(2e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=3\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "logits = model.predict(test_dataset).logits\n",
        "y_pred = tf.argmax(logits, axis=1)\n",
        "\n",
        "print(\"\\n=== mBERT Results ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moBeZa1TGJ04",
        "outputId": "a1408f34-e9a9-49e1-dbab-6fc06b580406"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: transformers==4.30.0 in /usr/local/lib/python3.11/dist-packages (4.30.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2025.3.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2025.4.26)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "92/92 [==============================] - 1554s 16s/step - loss: 0.6990 - accuracy: 0.4966 - val_loss: 0.6953 - val_accuracy: 0.5143\n",
            "Epoch 2/3\n",
            "92/92 [==============================] - 1512s 16s/step - loss: 0.6682 - accuracy: 0.5619 - val_loss: 0.6950 - val_accuracy: 0.5796\n",
            "Epoch 3/3\n",
            "92/92 [==============================] - 1489s 16s/step - loss: 0.6002 - accuracy: 0.6707 - val_loss: 0.6834 - val_accuracy: 0.6041\n",
            "31/31 [==============================] - 122s 4s/step\n",
            "\n",
            "=== mBERT Results ===\n",
            "Accuracy: 0.6041\n",
            "Precision: 0.5687\n",
            "Recall: 0.7647\n",
            "F1-score: 0.6523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaTokenizer, TFXLMRobertaForSequenceClassification\n",
        "\n",
        "# Load XLM-R tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Tokenize (same as mBERT)\n",
        "X_train_enc = encode_texts(X_train)  # Reuse the same function\n",
        "X_test_enc = encode_texts(X_test)\n",
        "\n",
        "# Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(X_train_enc),\n",
        "    y_train\n",
        ")).batch(8)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(X_test_enc),\n",
        "    y_test\n",
        ")).batch(8)\n",
        "\n",
        "# Load XLM-R model\n",
        "model = TFXLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
        "\n",
        "# Compile and train (same as mBERT)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(2e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=3\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "logits = model.predict(test_dataset).logits\n",
        "y_pred = tf.argmax(logits, axis=1)\n",
        "print(\"XLM-RoBERTa Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"recall_score: {recall_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463,
          "referenced_widgets": [
            "eed3ee501ea74c3c889fc8dd79fd013e",
            "208af020ef44413ca2c949a7cdf59eba",
            "3903500e20a14c70bc4ef69933639987",
            "15630a79f55744be92b8848e474b31e5",
            "49ea322473134858a7c5feefd83ee167",
            "838a3659b798405f8244fa00ea8008bc",
            "ddc42582b44e49c19ffc1b690fc0be4f",
            "7b6d1d987b4f48169c7085c0fb11c75a",
            "df844a4745e64c6a9769920da0eada90",
            "5db2288d97cc48cfb01abe10f849c0c2",
            "ff756ef93f124a5f9a715d15a1051178",
            "d67a7706a7fa4cd293a4fee12147ff03",
            "cf1a2ca505c04aaa8a2918b9bc0b15d6",
            "5033f4226c57491b9c0d995e1fd531d5",
            "cfedbb5998394d858f22bd0885cb3355",
            "898ea0969d2b4f7c96d2f635c7192df2",
            "b6cabb55d61547868f038edf8119c26b",
            "a8ceff1a3800410097846afc748ba55a",
            "50e44610568a4a45a6a8e5feaf9f3f28",
            "cdd6b0fdae57405ba8b9c3399fcd52c5",
            "580e27d26c264861a997229381d6abb5",
            "cc251a184ee84d26947f4f7308b3e1b1",
            "4b1287629b874e1a9407007901c86f92",
            "ec1719cdd6f24e47950de02b6de82209",
            "974e9bf88de549ccb16f5a036789e5e9",
            "204fec0578804b5c9028b831905d0293",
            "1b6f2c3d34814eea9a717f6854f969a3",
            "35660ad0df9a4edb959d1a8056f3a124",
            "3717edbe68c94507a9745e97e2d8401f",
            "917732e8b95444359d0aec78c07696e7",
            "6bb01edef217419b8138a2f07541697c",
            "20f01fcce132452cad346c182a729032",
            "c65a0b9df74f4fefba91a503a5cf9645",
            "af3ef09a491f420586469c486c3d7df7",
            "f51fd5f12fa9489cb08ed52bba167e54",
            "bbdd4fa5e2ef4494868dbc4bd408d172",
            "fd1c0f457f4a4828ac0bb34f408fc4de",
            "9ff096538ec2443eb4531fdeb9d2dd14",
            "e7b584f9e194446789f8eefe04232003",
            "734c1e9a90e94c48a750de6e80d60763",
            "b74d6fe14d3b4ca59d3b172365ee7f6a",
            "918820a8c5244d4896407348785e85b1",
            "155542cdebeb4942b0cdde83f6160484",
            "d951b675c636430097cf24acd6ca3726"
          ]
        },
        "id": "AADHw2Yz8PE8",
        "outputId": "677b5e5a-bd0f-4057-95c4-ea46def8e755"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed3ee501ea74c3c889fc8dd79fd013e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d67a7706a7fa4cd293a4fee12147ff03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b1287629b874e1a9407007901c86f92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af3ef09a491f420586469c486c3d7df7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'encode_texts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd961a9fbca5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Tokenize (same as mBERT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reuse the same function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encode_texts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --force-reinstall gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GuCYMy6d4Xqa",
        "outputId": "cd1ebf7b-5b1b-49cc-cad6-559fcfbd0026"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "smart_open",
                  "wrapt"
                ]
              },
              "id": "5922353217cb4e50be52abcec587a048"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####PART 1\n",
        "######Q2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re  # Added missing import\n",
        "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "\n",
        "# --- 1. Load and Prepare Data ---\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()[1:]  # Skip header\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            match = re.match(r\"^(.*)\\s([PN])$\", line)\n",
        "            if match:\n",
        "                text = match.group(1).strip()\n",
        "                label = 1 if match.group(2) == 'P' else 0\n",
        "                data.append((text, label))\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "\n",
        "# Load data\n",
        "df = load_data(\"urdu-sentiment-corpus-v1.tsv.txt\")\n",
        "\n",
        "# --- 2. Text Preprocessing ---\n",
        "# Basic text cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    return text.strip()\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['text'])\n",
        "\n",
        "# Padding\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "y = df['label'].values\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vocabulary size\n",
        "max_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# --- 3. Define Base BiLSTM Model ---\n",
        "def build_bilstm(embedding_matrix=None):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    if embedding_matrix is not None:\n",
        "        model.add(Embedding(\n",
        "            input_dim=embedding_matrix.shape[0],\n",
        "            output_dim=embedding_matrix.shape[1],\n",
        "            weights=[embedding_matrix],\n",
        "            input_length=max_len,\n",
        "            trainable=False))\n",
        "    else:\n",
        "        model.add(Embedding(\n",
        "            input_dim=max_words,\n",
        "            output_dim=256,\n",
        "            input_length=max_len))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# --- 4. Train/Prepare All Embeddings ---\n",
        "\n",
        "# Word2Vec\n",
        "print(\"Training Word2Vec...\")\n",
        "tokenized_texts = [text.split() for text in df['text']]\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_texts,\n",
        "    vector_size=300,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4)\n",
        "\n",
        "w2v_embedding = np.zeros((max_words, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words and word in w2v_model.wv:\n",
        "        w2v_embedding[i] = w2v_model.wv[word]\n",
        "\n",
        "# FastText\n",
        "print(\"Training FastText...\")\n",
        "ft_model = FastText(\n",
        "    sentences=tokenized_texts,\n",
        "    vector_size=300,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4)\n",
        "\n",
        "ft_embedding = np.zeros((max_words, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words and word in ft_model.wv:\n",
        "        ft_embedding[i] = ft_model.wv[word]\n",
        "\n",
        "# GloVe (Pretrained)\n",
        "print(\"Preparing GloVe...\")\n",
        "# First download glove.6B.300d.txt from https://nlp.stanford.edu/projects/glove/\n",
        "# Then convert to word2vec format\n",
        "if not os.path.exists('glove_word2vec_format.txt'):\n",
        "    glove2word2vec('glove.6B.300d.txt', 'glove_word2vec_format.txt')\n",
        "\n",
        "glove_model = KeyedVectors.load_word2vec_format('glove_word2vec_format.txt', binary=False)\n",
        "glove_embedding = np.zeros((max_words, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words and word in glove_model:\n",
        "        glove_embedding[i] = glove_model[word]\n",
        "\n",
        "# ELMo (Using TFHub)\n",
        "print(\"Preparing ELMo...\")\n",
        "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
        "def elmo_embed(texts):\n",
        "    return elmo.signatures[\"default\"](tf.constant(texts))[\"default\"]\n",
        "\n",
        "print(\"Creating ELMo embeddings for training set...\")\n",
        "batch_size = 32\n",
        "X_train_elmo = []\n",
        "\n",
        "# First, verify all indices are valid\n",
        "if max(X_train) >= len(df):\n",
        "    raise ValueError(\"X_train contains indices larger than the DataFrame\")\n",
        "\n",
        "for i in range(0, len(X_train), batch_size):\n",
        "    batch_indices = X_train[i:i+batch_size].tolist()\n",
        "    # Skip empty batches\n",
        "    if not batch_indices:\n",
        "        continue\n",
        "    batch = df['text'].iloc[batch_indices]\n",
        "    embeddings = elmo_embed(batch)\n",
        "    X_train_elmo.append(embeddings)\n",
        "\n",
        "X_train_elmo = np.concatenate(X_train_elmo) if X_train_elmo else np.array([])\n",
        "\n",
        "# Prepare ELMo embeddings for test set\n",
        "print(\"Creating ELMo embeddings for test set...\")\n",
        "X_test_elmo = []\n",
        "for i in range(0, len(X_test), batch_size):\n",
        "    batch = df['text'].iloc[X_test[i:i+batch_size].tolist()]\n",
        "    X_test_elmo.append(elmo_embed(batch))\n",
        "X_test_elmo = np.concatenate(X_test_elmo)\n",
        "\n",
        "# --- 5. Train and Evaluate All Models ---\n",
        "results = []\n",
        "\n",
        "# 1. Baseline (No Pretrained Embeddings)\n",
        "print(\"\\nEvaluating Baseline BiLSTM...\")\n",
        "model = build_bilstm()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "results.append({\n",
        "    'Model': 'BiLSTM (No Embedding)',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'F1': f1_score(y_test, y_pred)\n",
        "})\n",
        "\n",
        "# 2. Word2Vec\n",
        "print(\"\\nEvaluating Word2Vec BiLSTM...\")\n",
        "model = build_bilstm(w2v_embedding)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "results.append({\n",
        "    'Model': 'BiLSTM + Word2Vec',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'F1': f1_score(y_test, y_pred)\n",
        "})\n",
        "\n",
        "# 3. FastText\n",
        "print(\"\\nEvaluating FastText BiLSTM...\")\n",
        "model = build_bilstm(ft_embedding)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "results.append({\n",
        "    'Model': 'BiLSTM + FastText',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'F1': f1_score(y_test, y_pred)\n",
        "})\n",
        "\n",
        "# 4. GloVe\n",
        "print(\"\\nEvaluating GloVe BiLSTM...\")\n",
        "model = build_bilstm(glove_embedding)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "results.append({\n",
        "    'Model': 'BiLSTM + GloVe',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'F1': f1_score(y_test, y_pred)\n",
        "})\n",
        "\n",
        "# 5. ELMo\n",
        "print(\"\\nEvaluating ELMo Model...\")\n",
        "elmo_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(1024,)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "elmo_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "elmo_model.fit(\n",
        "    X_train_elmo, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1)\n",
        "\n",
        "y_pred = (elmo_model.predict(X_test_elmo) > 0.5).astype(int)\n",
        "results.append({\n",
        "    'Model': 'BiLSTM + ELMo',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred),\n",
        "    'Precision': precision_score(y_test, y_pred),\n",
        "    'Recall': recall_score(y_test, y_pred),\n",
        "    'F1': f1_score(y_test, y_pred)\n",
        "})\n",
        "\n",
        "# --- 6. Present Results ---\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n=== Final Results ===\")\n",
        "print(results_df.to_markdown(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(\"embedding_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "xuoU5KiV-KW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####PART 2\n",
        "#### Q3\n",
        "\n",
        "!pip install tensorflow nltk pandas scikit-learn\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "with open(\"/content/english-corpus.txt\", encoding='utf-8') as f:\n",
        "    english = f.read().splitlines()\n",
        "\n",
        "# Load Urdu sentences\n",
        "with open(\"/content/urdu-corpus.txt\", encoding='utf-8') as f:\n",
        "    urdu = f.read().splitlines()\n",
        "\n",
        "# Clean and normalize (optional, but useful)\n",
        "eng_sentences = [s.strip().lower() for s in english]\n",
        "urdu_sentences = [s.strip().lower() for s in urdu]\n",
        "\n",
        "\n",
        "# Optional: Lowercase\n",
        "eng_sentences = [s.lower() for s in eng_sentences]\n",
        "urdu_sentences = [s.lower() for s in urdu_sentences]\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize English\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(eng_sentences)\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
        "eng_pad = pad_sequences(eng_seq, padding='post')\n",
        "\n",
        "# Tokenize Urdu\n",
        "urdu_tokenizer = Tokenizer()\n",
        "urdu_tokenizer.fit_on_texts(urdu_sentences)\n",
        "urdu_seq = urdu_tokenizer.texts_to_sequences(urdu_sentences)\n",
        "urdu_pad = pad_sequences(urdu_seq, padding='post')\n",
        "\n",
        "# Vocab sizes\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "urdu_vocab_size = len(urdu_tokenizer.word_index) + 1\n",
        "\n",
        "# Pad lengths\n",
        "eng_max_len = eng_pad.shape[1]\n",
        "urdu_max_len = urdu_pad.shape[1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(eng_pad, urdu_pad, test_size=0.1)\n",
        "\n",
        "\n",
        "####MODEL RNN TO SEQTOSEQ\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_rnn_model():\n",
        "    encoder_inputs = Input(shape=(eng_max_len,))\n",
        "    x = Embedding(eng_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
        "    encoder = SimpleRNN(256, return_state=True)\n",
        "    encoder_outputs, state_h = encoder(x)\n",
        "\n",
        "    decoder_inputs = Input(shape=(urdu_max_len,))\n",
        "    y = Embedding(urdu_vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
        "    decoder_rnn = SimpleRNN(256, return_sequences=True)\n",
        "    decoder_outputs = decoder_rnn(y, initial_state=state_h)\n",
        "    decoder_dense = Dense(urdu_vocab_size, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "#######Model 2: Bi-RNN Seq2Seq\n",
        "def build_birnn_model():\n",
        "    encoder_inputs = Input(shape=(eng_max_len,))\n",
        "    x = Embedding(eng_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
        "    encoder = Bidirectional(SimpleRNN(256, return_state=True))\n",
        "    encoder_outputs, forward_h, backward_h = encoder(x)\n",
        "    state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "\n",
        "    decoder_inputs = Input(shape=(urdu_max_len,))\n",
        "    y = Embedding(urdu_vocab_size, 512, mask_zero=True)(decoder_inputs)\n",
        "    decoder_rnn = SimpleRNN(512, return_sequences=True)\n",
        "    decoder_outputs = decoder_rnn(y, initial_state=state_h)\n",
        "    decoder_dense = Dense(urdu_vocab_size, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "#Model 3: LSTM Seq2Seq\n",
        "\n",
        "def build_lstm_model():\n",
        "    encoder_inputs = Input(shape=(eng_max_len,))\n",
        "    x = Embedding(eng_vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
        "    encoder_lstm, state_h, state_c = LSTM(256, return_state=True)(x)\n",
        "\n",
        "    decoder_inputs = Input(shape=(urdu_max_len,))\n",
        "    y = Embedding(urdu_vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
        "    decoder_lstm = LSTM(256, return_sequences=True)\n",
        "    decoder_outputs = decoder_lstm(y, initial_state=[state_h, state_c])\n",
        "    decoder_dense = Dense(urdu_vocab_size, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "##Model 4: Transformer Model (Simple)\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout\n",
        "\n",
        "def build_transformer_model():\n",
        "    inputs = Input(shape=(eng_max_len,))\n",
        "    x = Embedding(eng_vocab_size, 256)(inputs)\n",
        "\n",
        "    attn = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
        "    attn = Dropout(0.1)(attn)\n",
        "    x = LayerNormalization()(x + attn)\n",
        "\n",
        "    ffn = Dense(512, activation='relu')(x)\n",
        "    ffn = Dense(256)(ffn)\n",
        "    x = LayerNormalization()(x + ffn)\n",
        "\n",
        "    outputs = Dense(urdu_vocab_size, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "###Training Function (Fair for All Models\n",
        "\n",
        "###evaluation with bleu score\n",
        "def train_model(model, name):\n",
        "    history = model.fit(\n",
        "        [X_train, y_train], y_train.reshape(y_train.shape[0], y_train.shape[1], 1),\n",
        "        validation_split=0.1,\n",
        "        epochs=2,\n",
        "        batch_size=64\n",
        "    )\n",
        "    model.save(f\"{name}_model.h5\")\n",
        "    return history\n",
        "\n",
        "###Final BLEU Score Table and Inference\n",
        "\n",
        "models = {\n",
        "    \"RNN\": build_rnn_model(),\n",
        "    \"BiRNN\": build_birnn_model(),\n",
        "    \"LSTM\": build_lstm_model(),\n",
        "    \"Transformer\": build_transformer_model()\n",
        "}\n",
        "\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer_urdu = Tokenizer()\n",
        "tokenizer_urdu.fit_on_texts(urdu_sentences)  # urdu_sentences = list of Urdu strings\n",
        "\n",
        "# Convert text to sequences\n",
        "urdu_sequences = tokenizer_urdu.texts_to_sequences(urdu_sentences)\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, tokenizer_urdu, max_len_urdu):\n",
        "    smooth_fn = SmoothingFunction().method1\n",
        "    bleu_scores = []\n",
        "\n",
        "    for i in range(len(X_test)):\n",
        "        # Predict translation\n",
        "        prediction = model.predict(np.array([X_test[i]]))\n",
        "        predicted_seq = np.argmax(prediction[0], axis=-1)\n",
        "\n",
        "        # Convert indices to words\n",
        "        pred_tokens = [tokenizer_urdu.index_word.get(idx, '') for idx in predicted_seq if idx != 0]\n",
        "        ref_tokens = [tokenizer_urdu.index_word.get(idx, '') for idx in y_test[i] if idx != 0]\n",
        "\n",
        "        # Calculate BLEU score\n",
        "        bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smooth_fn)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "    return np.mean(bleu_scores)\n",
        "\n",
        "bleu_scores = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    train_model(model, name)\n",
        "    bleu = evaluate_model(model, X_test[:100], y_test[:100], tokenizer_urdu, max_len_urdu)\n",
        "    bleu_scores[name] = bleu\n",
        "    print(f\"{name} BLEU Score: {bleu}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlZGO0xDCv01",
        "outputId": "0de755f0-1618-4040-f4d0-648f63bf2fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN...\n",
            "Epoch 1/2\n",
            "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 1s/step - accuracy: 0.0705 - loss: 5.5428 - val_accuracy: 0.1979 - val_loss: 1.9873\n",
            "Epoch 2/2\n",
            "\u001b[1m279/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.2086 - loss: 1.6157"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###PART2\n",
        "##Q4\n",
        "def load_glove_embeddings(glove_file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coeffs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coeffs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('/content/glove.6B.300d.txt')\n",
        "\n",
        "###Create Embedding Matrix (matching your tokenizer)\n",
        "tokenizer_eng = Tokenizer()\n",
        "tokenizer_eng.fit_on_texts(eng_sentences)\n",
        "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size_eng, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer_eng.word_index.items():\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "def build_rnn_model_random(vocab_size_eng, vocab_size_urdu, max_len_eng, max_len_urdu, embedding_dim=100):\n",
        "    encoder_inputs = Input(shape=(max_len_eng,))\n",
        "    x = Embedding(vocab_size_eng, embedding_dim)(encoder_inputs)\n",
        "    encoder = SimpleRNN(256, return_sequences=False, return_state=True)\n",
        "    encoder_output, state_h = encoder(x)\n",
        "\n",
        "    decoder_inputs = Input(shape=(max_len_urdu,))\n",
        "    decoder_embedding = Embedding(vocab_size_urdu, embedding_dim)(decoder_inputs)\n",
        "    decoder_rnn = SimpleRNN(256, return_sequences=True)\n",
        "    decoder_output = decoder_rnn(decoder_embedding, initial_state=state_h)\n",
        "\n",
        "    output = TimeDistributed(Dense(vocab_size_urdu, activation='softmax'))(decoder_output)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_rnn_model_glove(vocab_size_eng, vocab_size_urdu, max_len_eng, max_len_urdu, embedding_matrix):\n",
        "    encoder_inputs = Input(shape=(max_len_eng,))\n",
        "    x = Embedding(vocab_size_eng, embedding_matrix.shape[1],\n",
        "                  weights=[embedding_matrix], trainable=False)(encoder_inputs)\n",
        "    encoder = SimpleRNN(256, return_sequences=False, return_state=True)\n",
        "    encoder_output, state_h = encoder(x)\n",
        "\n",
        "    decoder_inputs = Input(shape=(max_len_urdu,))\n",
        "    decoder_embedding = Embedding(vocab_size_urdu, embedding_matrix.shape[1])(decoder_inputs)\n",
        "    decoder_rnn = SimpleRNN(256, return_sequences=True)\n",
        "    decoder_output = decoder_rnn(decoder_embedding, initial_state=state_h)\n",
        "\n",
        "    output = TimeDistributed(Dense(vocab_size_urdu, activation='softmax'))(decoder_output)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "##trainning both models\n",
        "\n",
        "# Prepare input/output sequences\n",
        "# Assume X_train_eng, X_train_urdu_input, and y_train_urdu_output are ready\n",
        "\n",
        "model_random = build_rnn_model_random(vocab_size_eng, vocab_size_urdu, max_len_eng, max_len_urdu)\n",
        "model_random.fit([X_train_eng, X_train_urdu_input], y_train_urdu_output, epochs=50, batch_size=64)\n",
        "\n",
        "model_glove = build_rnn_model_glove(vocab_size_eng, vocab_size_urdu, max_len_eng, max_len_urdu, embedding_matrix)\n",
        "model_glove.fit([X_train_eng, X_train_urdu_input], y_train_urdu_output, epochs=50, batch_size=64)\n",
        "\n",
        "\n",
        "bleu_random = evaluate_model(model_random, X_test_eng, y_test_urdu, tokenizer_urdu, max_len_urdu)\n",
        "bleu_glove = evaluate_model(model_glove, X_test_eng, y_test_urdu, tokenizer_urdu, max_len_urdu)\n",
        "\n",
        "print(f\"Random Embedding BLEU Score: {bleu_random:.4f}\")\n",
        "print(f\"GloVe Embedding BLEU Score: {bleu_glove:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Tm5zoSgNUDBD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}